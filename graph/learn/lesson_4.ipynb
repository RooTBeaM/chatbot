{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from tavily import TavilyClient\n",
    "\n",
    "# load environment variables from .env file\n",
    "_ = load_dotenv(\"../.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated\n",
    "import operator\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "# from langchain_ollama import ChatOllama\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = TavilySearchResults(max_results=2)\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, model, tools, checkpointer, system=\"\"):\n",
    "        self.system = system\n",
    "        graph = StateGraph(AgentState)\n",
    "        graph.add_node(\"llm\", self.call_openai)\n",
    "        graph.add_node(\"action\", self.take_action)\n",
    "        graph.add_conditional_edges(\n",
    "            \"llm\", self.exists_action, {True: \"action\", False: END}\n",
    "        )\n",
    "        graph.add_edge(\"action\", \"llm\")\n",
    "        graph.set_entry_point(\"llm\")\n",
    "        self.graph = graph.compile(checkpointer=checkpointer)\n",
    "        self.tools = {t.name: t for t in tools}\n",
    "        self.model = model.bind_tools(tools)\n",
    "\n",
    "    def call_openai(self, state: AgentState):\n",
    "        messages = state[\"messages\"]\n",
    "        if self.system:\n",
    "            messages = [SystemMessage(content=self.system)] + messages\n",
    "        message = self.model.invoke(messages)\n",
    "        return {\"messages\": [message]}\n",
    "\n",
    "    def exists_action(self, state: AgentState):\n",
    "        result = state[\"messages\"][-1]\n",
    "        return len(result.tool_calls) > 0\n",
    "\n",
    "    def take_action(self, state: AgentState):\n",
    "        tool_calls = state[\"messages\"][-1].tool_calls\n",
    "        results = []\n",
    "        for t in tool_calls:\n",
    "            print(f\"Calling: {t}\")\n",
    "            result = self.tools[t[\"name\"]].invoke(t[\"args\"])\n",
    "            results.append(\n",
    "                ToolMessage(tool_call_id=t[\"id\"], name=t[\"name\"], content=str(result))\n",
    "            )\n",
    "        print(\"Back to the model!\")\n",
    "        return {\"messages\": results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are a smart research assistant. Use the search engine to look up information. \\\n",
    "You are allowed to make multiple calls (either together or in sequence). \\\n",
    "Only look up information when you are sure of what you want. \\\n",
    "If you need to look up some information before asking a follow up question, you are allowed to do that!\n",
    "\"\"\"\n",
    "# model = ChatOllama(model=\"llama3.2\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    api_key=\"ollama\",\n",
    "    model=\"llama3.2\",\n",
    "    base_url=\"http://localhost:11434/v1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 26, 'total_tokens': 36, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'llama3.2', 'system_fingerprint': 'fp_ollama', 'finish_reason': 'stop', 'logprobs': None}, id='run-99c01f5b-f4ea-4396-9217-64c36a69cdbc-0', usage_metadata={'input_tokens': 26, 'output_tokens': 10, 'total_tokens': 36, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [HumanMessage(content=\"What is the weather in sf?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "with SqliteSaver.from_conn_string(\":memory:\") as checkpointer:\n",
    "    abot = Agent(llm, [tool], system=prompt, checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_9wl0ka1l', 'function': {'arguments': '{\"query\":\"sf weather\"}', 'name': 'tavily_search_results_json'}, 'type': 'function', 'index': 0}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 258, 'total_tokens': 280, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'llama3.2', 'system_fingerprint': 'fp_ollama', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-6ee89159-0795-49ca-97e3-a1757657395b-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'sf weather'}, 'id': 'call_9wl0ka1l', 'type': 'tool_call'}], usage_metadata={'input_tokens': 258, 'output_tokens': 22, 'total_tokens': 280, 'input_token_details': {}, 'output_token_details': {}})]\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'sf weather'}, 'id': 'call_9wl0ka1l', 'type': 'tool_call'}\n",
      "Back to the model!\n",
      "[ToolMessage(content='[{\\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'San Francisco\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 37.775, \\'lon\\': -122.4183, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1739771633, \\'localtime\\': \\'2025-02-16 21:53\\'}, \\'current\\': {\\'last_updated_epoch\\': 1739771100, \\'last_updated\\': \\'2025-02-16 21:45\\', \\'temp_c\\': 12.2, \\'temp_f\\': 54.0, \\'is_day\\': 0, \\'condition\\': {\\'text\\': \\'Overcast\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/night/122.png\\', \\'code\\': 1009}, \\'wind_mph\\': 4.5, \\'wind_kph\\': 7.2, \\'wind_degree\\': 290, \\'wind_dir\\': \\'WNW\\', \\'pressure_mb\\': 1020.0, \\'pressure_in\\': 30.11, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 97, \\'cloud\\': 100, \\'feelslike_c\\': 11.7, \\'feelslike_f\\': 53.1, \\'windchill_c\\': 11.2, \\'windchill_f\\': 52.2, \\'heatindex_c\\': 11.3, \\'heatindex_f\\': 52.4, \\'dewpoint_c\\': 10.9, \\'dewpoint_f\\': 51.6, \\'vis_km\\': 16.0, \\'vis_miles\\': 9.0, \\'uv\\': 0.0, \\'gust_mph\\': 6.9, \\'gust_kph\\': 11.2}}\"}, {\\'url\\': \\'https://www.weather2travel.com/california/san-francisco/february/\\', \\'content\\': \"San Francisco weather in February 2025 | California Holidays San Francisco weather in February 2025 Expect 16°C daytime maximum temperatures in the shade with on average 7 hours of sunshine per day in San Francisco in February. There are usually 9 days with some rain in San Francisco in February and the average monthly rainfall is 91mm. Get your weekly fix of holiday inspiration from some of the world\\'s best travel writers plus save on your next trip with the latest exclusive offers More holidays January sales Handpicked travel deals & holiday discounts We help you find the best travel deals for your holiday in the sun by sharing tips on when and where to go, before providing you with top discounts. Holidays\"}]', name='tavily_search_results_json', tool_call_id='call_9wl0ka1l')]\n",
      "[AIMessage(content=\"The current weather in San Francisco is overcast with a temperature of 12.2°C (54.0°F). There is a moderate wind blowing at 4.5 mph (7.2 km/h) from the west-northwest direction. The pressure is 1020.0 mb, and the humidity is 97%. It's also quite cloudy with a visibility of 16.0 km.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 84, 'prompt_tokens': 737, 'total_tokens': 821, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'llama3.2', 'system_fingerprint': 'fp_ollama', 'finish_reason': 'stop', 'logprobs': None}, id='run-59e705d1-eb42-4780-8b7d-164d148246c1-0', usage_metadata={'input_tokens': 737, 'output_tokens': 84, 'total_tokens': 821, 'input_token_details': {}, 'output_token_details': {}})]\n"
     ]
    }
   ],
   "source": [
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v[\"messages\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_7e33wt1d', 'function': {'arguments': '{\"query\":\"los angeles weather February 2025\"}', 'name': 'tavily_search_results_json'}, 'type': 'function', 'index': 0}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 964, 'total_tokens': 992, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'llama3.2', 'system_fingerprint': 'fp_ollama', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-c253e3ac-0d0f-4220-a727-fbf228d08c8f-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'los angeles weather February 2025'}, 'id': 'call_7e33wt1d', 'type': 'tool_call'}], usage_metadata={'input_tokens': 964, 'output_tokens': 28, 'total_tokens': 992, 'input_token_details': {}, 'output_token_details': {}})]}\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'los angeles weather February 2025'}, 'id': 'call_7e33wt1d', 'type': 'tool_call'}\n",
      "Back to the model!\n",
      "{'messages': [ToolMessage(content='[{\\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'Los Angeles\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 34.0522, \\'lon\\': -118.2428, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1739771669, \\'localtime\\': \\'2025-02-16 21:54\\'}, \\'current\\': {\\'last_updated_epoch\\': 1739771100, \\'last_updated\\': \\'2025-02-16 21:45\\', \\'temp_c\\': 13.9, \\'temp_f\\': 57.0, \\'is_day\\': 0, \\'condition\\': {\\'text\\': \\'Clear\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/night/113.png\\', \\'code\\': 1000}, \\'wind_mph\\': 2.2, \\'wind_kph\\': 3.6, \\'wind_degree\\': 271, \\'wind_dir\\': \\'W\\', \\'pressure_mb\\': 1015.0, \\'pressure_in\\': 29.97, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 77, \\'cloud\\': 0, \\'feelslike_c\\': 14.6, \\'feelslike_f\\': 58.2, \\'windchill_c\\': 15.1, \\'windchill_f\\': 59.1, \\'heatindex_c\\': 15.2, \\'heatindex_f\\': 59.3, \\'dewpoint_c\\': 11.2, \\'dewpoint_f\\': 52.2, \\'vis_km\\': 16.0, \\'vis_miles\\': 9.0, \\'uv\\': 0.0, \\'gust_mph\\': 6.7, \\'gust_kph\\': 10.8}}\"}, {\\'url\\': \\'https://world-weather.info/forecast/usa/los_angeles/february-2025/\\', \\'content\\': \"Weather in Los Angeles in February 2025 (California) - Detailed Weather Forecast for a Month Weather Weather in Los Angeles Weather in Los Angeles in February 2025 Los Angeles Weather Forecast for February 2025 is based on long term prognosis and previous years\\' statistical data. 1 +64°+46° 2 +66°+52° 3 +63°+48° 4 +61°+50° 5 +61°+52° 6 +59°+57° 7 +59°+57° 8 +63°+50° 9 +66°+52° 10 +61°+50° 11 +59°+52° 12 +57°+50° 13 +57°+50° 14 +61°+50° 15 +66°+46° 16 +68°+50° 17 +66°+50° 18 +75°+54° 19 +73°+63° 20 +72°+64° 21 +66°+61° 22 +63°+57° +63°+52° +63°+52° +63°+52° +64°+54° +63°+54° +64°+54° Extended weather forecast in Los Angeles Weather in Washington, D.C.+39° Sacramento+52° Norwalk+57° Pasadena+55° Rosemead+57° Inglewood+57° Bellflower+57° Burbank+55° Compton+57° Bandini+57° world\\'s temperature today Temperature units\"}]', name='tavily_search_results_json', tool_call_id='call_7e33wt1d')]}\n",
      "{'messages': [AIMessage(content=\"The current weather in Los Angeles is clear with a temperature of 13.9°C (57.0°F). There is a gentle wind blowing at 2.2 mph (3.6 km/h) from the west direction. The pressure is 1015.0 mb, and the humidity is 77%. It's also quite sunny with a visibility of 16.0 km.\\n\\nAccording to the detailed weather forecast for February 2025, the temperature in Los Angeles will vary between 13.9°C (57.0°F) and 75°C (167°F) throughout the month, with plenty of sunshine expected throughout.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 130, 'prompt_tokens': 1646, 'total_tokens': 1776, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'llama3.2', 'system_fingerprint': 'fp_ollama', 'finish_reason': 'stop', 'logprobs': None}, id='run-191f109e-6914-4488-bbe5-5259604fc78d-0', usage_metadata={'input_tokens': 1646, 'output_tokens': 130, 'total_tokens': 1776, 'input_token_details': {}, 'output_token_details': {}})]}\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"What about in la?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_nsf20evc', 'function': {'arguments': '{\"query\":\"warmest month in Los Angeles vs San Francisco\"}', 'name': 'tavily_search_results_json'}, 'type': 'function', 'index': 0}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 1919, 'total_tokens': 1948, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'llama3.2', 'system_fingerprint': 'fp_ollama', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-5669d124-2612-42be-a112-4dd55cf5dd54-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'warmest month in Los Angeles vs San Francisco'}, 'id': 'call_nsf20evc', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1919, 'output_tokens': 29, 'total_tokens': 1948, 'input_token_details': {}, 'output_token_details': {}})]}\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'warmest month in Los Angeles vs San Francisco'}, 'id': 'call_nsf20evc', 'type': 'tool_call'}\n",
      "Back to the model!\n",
      "{'messages': [ToolMessage(content=\"[{'url': 'https://www.servicemasterrestore.com/servicemaster-restoration-by-emt-orange-county/why-us/blog/2022/april/10-cities-in-california-with-the-best-weather/', 'content': 'While the rest of the country experiences the start of a cool autumn, September and October in San Francisco are the warmest and sunniest months'}, {'url': 'https://weatherspark.com/compare/y/557~1705/Comparison-of-the-Average-Weather-in-San-Francisco-and-Los-Angeles', 'content': 'Compare the Climate and Weather in San Francisco and Los Angeles This page lets you compare and contrast the weather and climate in San Francisco and Los Angeles year round. Low Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec Clearer Skies   Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec Rainfall    Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec Muggy days  Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec Wind Speed (mph)    Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec Solar Energy (kWh)  Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec'}]\", name='tavily_search_results_json', tool_call_id='call_nsf20evc')]}\n",
      "{'messages': [AIMessage(content='Los Angeles is generally warmer than San Francisco. According to the weather comparison, Los Angeles has a higher average temperature throughout the year, especially during the summer months. San Francisco, on the other hand, has cooler and sunnier months in September and October, which are its warmest and sunniest months.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 62, 'prompt_tokens': 2048, 'total_tokens': 2110, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'llama3.2', 'system_fingerprint': 'fp_ollama', 'finish_reason': 'stop', 'logprobs': None}, id='run-642a5003-39a9-4dc1-9c36-7f355d84a67d-0', usage_metadata={'input_tokens': 2048, 'output_tokens': 62, 'total_tokens': 2110, 'input_token_details': {}, 'output_token_details': {}})]}\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"Which one is warmer?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_9l5l70at', 'function': {'arguments': '{\"query\":\"which one is warmer\"}', 'name': 'tavily_search_results_json'}, 'type': 'function', 'index': 0}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 256, 'total_tokens': 280, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'llama3.2', 'system_fingerprint': 'fp_ollama', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-d96940f7-0d1d-421e-9832-d6143a584124-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'which one is warmer'}, 'id': 'call_9l5l70at', 'type': 'tool_call'}], usage_metadata={'input_tokens': 256, 'output_tokens': 24, 'total_tokens': 280, 'input_token_details': {}, 'output_token_details': {}})]}\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'which one is warmer'}, 'id': 'call_9l5l70at', 'type': 'tool_call'}\n",
      "Back to the model!\n",
      "{'messages': [ToolMessage(content=\"[{'url': 'https://brainly.com/question/30896240', 'content': '-5° Celsius is warmer than -8 degrees Celsius. This is because -5 degrees Celsius is closer to 0 degrees Celsius, which is the temperature'}, {'url': 'https://languageandgrammar.com/2010/04/07/warmer-and-colder-temperartures/', 'content': 'Technically, temperatures cannot be warmer or colder. A temperature is a number, which means that it can be higher or lower, not warmer or colder.'}]\", name='tavily_search_results_json', tool_call_id='call_9l5l70at')]}\n",
      "{'messages': [AIMessage(content='Based on the search results, it seems that there is some ambiguity in the question. The first result from Brainly suggests that -5°C is warmer than -8°C, but this is more of a relative comparison rather than a direct answer to which one is warmer. The second result from Language and Grammar states that temperatures cannot be \"warmer\" or \"colder\", as these are not numerical values.\\n\\nTo provide a neutral response: without more information on the specific context or unit of measurement, it\\'s difficult to definitively say which temperature is warmer.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 113, 'prompt_tokens': 276, 'total_tokens': 389, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'llama3.2', 'system_fingerprint': 'fp_ollama', 'finish_reason': 'stop', 'logprobs': None}, id='run-3af29767-5d54-4556-ba42-149030fc221c-0', usage_metadata={'input_tokens': 276, 'output_tokens': 113, 'total_tokens': 389, 'input_token_details': {}, 'output_token_details': {}})]}\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"Which one is warmer?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
