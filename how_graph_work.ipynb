{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\panya\\anaconda3\\envs\\chat\\Lib\\site-packages\\langsmith\\client.py:256: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.tools import BaseTool, StructuredTool, Tool, tool\n",
    "\n",
    "import random\n",
    "\n",
    "@tool(\"lower_case\", return_direct=True)\n",
    "def to_lower_case(input:str) -> str:\n",
    "  \"\"\"Returns the input as all lower case.\"\"\"\n",
    "  return input.lower()\n",
    "\n",
    "@tool(\"upper_case\", return_direct=True)\n",
    "def to_upper_case(input:str) -> str:\n",
    "  \"\"\"Returns the input as all upper case.\"\"\"\n",
    "  return input.upper()\n",
    "\n",
    "@tool(\"random_number\", return_direct=True)\n",
    "def random_number_maker() -> int:\n",
    "    \"\"\"Returns a random float number between 0-100.\"\"\"\n",
    "    # return random.randint(0, 100)\n",
    "    return round(random.randint(0, 100) + random.random(),2)\n",
    "\n",
    "tools = [to_lower_case,to_upper_case,random_number_maker]\n",
    "\n",
    "from langchain import hub\n",
    " # prompt = hub.pull(\"anthonydresser/structured-chat-agent-llama\")\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.22"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(random.randint(0, 100) + random.random(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "You are a helpful assistant\n",
      "\n",
      "=============================\u001b[1m Messages Placeholder \u001b[0m=============================\n",
      "\n",
      "\u001b[33;1m\u001b[1;3m{chat_history}\u001b[0m\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "\u001b[33;1m\u001b[1;3m{input}\u001b[0m\n",
      "\n",
      "=============================\u001b[1m Messages Placeholder \u001b[0m=============================\n",
      "\n",
      "\u001b[33;1m\u001b[1;3m{agent_scratchpad}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "prompt.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "# llm = ChatOllama(model=\"llama3.2:latest\", temperature=0)\n",
    "# llm = ChatOllama(model=\"llama3.1:latest\", temperature=0)\n",
    "llm = ChatOllama(model=\"qwen2.5:7b\", temperature=0.1)\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Sad', additional_kwargs={}, response_metadata={'model': 'qwen2.5:7b', 'created_at': '2025-01-16T17:15:55.7929356Z', 'done': True, 'done_reason': 'stop', 'total_duration': 113483900, 'load_duration': 17435200, 'prompt_eval_count': 53, 'prompt_eval_duration': 17000000, 'eval_count': 2, 'eval_duration': 71000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-5eb33948-d697-4cf6-a457-826ce920a64f-0', usage_metadata={'input_tokens': 53, 'output_tokens': 2, 'total_tokens': 55})"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  test ChatPromptTemplate\n",
    "from langchain.prompts.chat import (\n",
    "ChatPromptTemplate,\n",
    "SystemMessagePromptTemplate,\n",
    "AIMessagePromptTemplate,\n",
    "HumanMessagePromptTemplate,)\n",
    "template=\"You are a helpful assistant who can give {category} for given input. Only give {category} no other text, use as little words as possible while responding, better give reply only in one word.\"\n",
    "system_message_prompt=SystemMessagePromptTemplate.from_template(template)\n",
    "human_template=\"{text}\"\n",
    "human_message_prompt=HumanMessagePromptTemplate.from_template(human_template)\n",
    "chat_prompt=ChatPromptTemplate.from_messages([system_message_prompt,human_message_prompt])\n",
    "\n",
    "t = chat_prompt.format_prompt(category=\"antonyms\", text=\"Happy\").to_messages()\n",
    "llm.invoke(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = prompt.format_prompt(\n",
    "    input=\"give me a random number and then write in words and make it lower case.\", \n",
    "    chat_history=[],\n",
    "    agent_scratchpad=[]\n",
    "    ).to_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "from langgraph.graph import START,END, StateGraph\n",
    "from langgraph.prebuilt import ToolNode,tools_condition\n",
    "\n",
    "tool_executor = ToolNode(tools)\n",
    "# Node\n",
    "def reasoner(state: MessagesState):\n",
    "   return {\"messages\": [llm_with_tools.invoke([\"You are a helpful assistant. result must be number in word\"] + state[\"messages\"])]}\n",
    "\n",
    "# Graph\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "# Add nodes\n",
    "builder.add_node(\"reasoner\", reasoner)\n",
    "builder.add_node(\"tools\", ToolNode(tools)) # for the tools\n",
    "\n",
    "# Add edges\n",
    "builder.add_edge(START, \"reasoner\")\n",
    "builder.add_conditional_edges(\n",
    "    \"reasoner\",\n",
    "    # If the latest message (result) from node reasoner is a tool call -> tools_condition routes to tools\n",
    "    # If the latest message (result) from node reasoner is a not a tool call -> tools_condition routes to END\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\", \"reasoner\")\n",
    "app = builder.compile()\n",
    "# app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'qwen2.5:7b', 'created_at': '2025-01-16T17:16:01.0537722Z', 'done': True, 'done_reason': 'stop', 'total_duration': 611958400, 'load_duration': 18333500, 'prompt_eval_count': 276, 'prompt_eval_duration': 59000000, 'eval_count': 16, 'eval_duration': 530000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-a924d6cd-61ec-4610-ae02-93ddd12e9993-0', tool_calls=[{'name': 'random_number', 'args': {}, 'id': '732dcaee-a5a4-4666-8a07-124db253743e', 'type': 'tool_call'}], usage_metadata={'input_tokens': 276, 'output_tokens': 16, 'total_tokens': 292})]}\n",
      "----\n",
      "{'messages': [ToolMessage(content='69.91', name='random_number', id='98105e50-0111-4c4d-b935-a7bd16c80917', tool_call_id='732dcaee-a5a4-4666-8a07-124db253743e')]}\n",
      "----\n",
      "{'messages': [AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'qwen2.5:7b', 'created_at': '2025-01-16T17:16:01.6667243Z', 'done': True, 'done_reason': 'stop', 'total_duration': 608992600, 'load_duration': 16254000, 'prompt_eval_count': 315, 'prompt_eval_duration': 13000000, 'eval_count': 25, 'eval_duration': 568000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-a005104f-cfa0-443f-b7fe-44c3e26c9f7d-0', tool_calls=[{'name': 'lower_case', 'args': {'input': 'sixty-nine point nine one'}, 'id': '7a1bdfc9-e575-4fdb-9e42-e18269c1add5', 'type': 'tool_call'}], usage_metadata={'input_tokens': 315, 'output_tokens': 25, 'total_tokens': 340})]}\n",
      "----\n",
      "{'messages': [ToolMessage(content='sixty-nine point nine one', name='lower_case', id='bf41b3f9-0d08-4792-818b-b2a899a27558', tool_call_id='7a1bdfc9-e575-4fdb-9e42-e18269c1add5')]}\n",
      "----\n",
      "{'messages': [AIMessage(content='the random number you requested is \"sixty-nine point nine one\" in lower case.', additional_kwargs={}, response_metadata={'model': 'qwen2.5:7b', 'created_at': '2025-01-16T17:16:02.153812Z', 'done': True, 'done_reason': 'stop', 'total_duration': 482941900, 'load_duration': 16865600, 'prompt_eval_count': 363, 'prompt_eval_duration': 13000000, 'eval_count': 19, 'eval_duration': 434000000, 'message': Message(role='assistant', content='the random number you requested is \"sixty-nine point nine one\" in lower case.', images=None, tool_calls=None)}, id='run-7557b5bb-02b3-4b0a-be24-ce1631a15b16-0', usage_metadata={'input_tokens': 363, 'output_tokens': 19, 'total_tokens': 382})]}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"messages\": \"give me a random number and then write in words and make it lower case.\"}\n",
    "for s in app.stream(inputs):\n",
    "    print(list(s.values())[0])\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'qwen2.5:7b', 'created_at': '2025-01-16T17:16:59.745471Z', 'done': True, 'done_reason': 'stop', 'total_duration': 617988000, 'load_duration': 17011400, 'prompt_eval_count': 273, 'prompt_eval_duration': 142000000, 'eval_count': 16, 'eval_duration': 451000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-5a99bb97-a84a-467c-a3e8-4be196d1f67e-0', tool_calls=[{'name': 'random_number', 'args': {}, 'id': '6a6014de-2293-4806-9010-8716bc6c63f7', 'type': 'tool_call'}], usage_metadata={'input_tokens': 273, 'output_tokens': 16, 'total_tokens': 289})]}\n",
      "----\n",
      "{'messages': [ToolMessage(content='38.05', name='random_number', id='1c0cf78a-3d4a-4f02-a9e2-ec981cbcd6c2', tool_call_id='6a6014de-2293-4806-9010-8716bc6c63f7')]}\n",
      "----\n",
      "{'messages': [AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'qwen2.5:7b', 'created_at': '2025-01-16T17:17:00.3462705Z', 'done': True, 'done_reason': 'stop', 'total_duration': 596903300, 'load_duration': 17902900, 'prompt_eval_count': 312, 'prompt_eval_duration': 14000000, 'eval_count': 25, 'eval_duration': 556000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-e477dbdd-cf20-4bb6-b52e-6efa4d61362f-0', tool_calls=[{'name': 'lower_case', 'args': {'input': 'thirty-eight point zero five'}, 'id': 'ccdef30f-1d8c-4eca-b435-7aede03cd3be', 'type': 'tool_call'}], usage_metadata={'input_tokens': 312, 'output_tokens': 25, 'total_tokens': 337})]}\n",
      "----\n",
      "{'messages': [ToolMessage(content='thirty-eight point zero five', name='lower_case', id='5e807021-9968-49db-b3e7-ecebf5428bf7', tool_call_id='ccdef30f-1d8c-4eca-b435-7aede03cd3be')]}\n",
      "----\n",
      "{'messages': [AIMessage(content='The random number generated is thirty-eight point zero five. \\n\\nIn lower case words, it is: thirty-eight point zero five.', additional_kwargs={}, response_metadata={'model': 'qwen2.5:7b', 'created_at': '2025-01-16T17:17:01.0166994Z', 'done': True, 'done_reason': 'stop', 'total_duration': 666029600, 'load_duration': 16777200, 'prompt_eval_count': 360, 'prompt_eval_duration': 12000000, 'eval_count': 27, 'eval_duration': 620000000, 'message': Message(role='assistant', content='The random number generated is thirty-eight point zero five. \\n\\nIn lower case words, it is: thirty-eight point zero five.', images=None, tool_calls=None)}, id='run-39342a74-0e6c-4ed0-9d77-6c7b578335ab-0', usage_metadata={'input_tokens': 360, 'output_tokens': 27, 'total_tokens': 387})]}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"messages\": \"give me a random number and then write in lower case words.\"}\n",
    "for s in app.stream(inputs):\n",
    "    print(list(s.values())[0])\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'qwen2.5:7b', 'created_at': '2025-01-16T17:17:15.1921723Z', 'done': True, 'done_reason': 'stop', 'total_duration': 697404300, 'load_duration': 17978700, 'prompt_eval_count': 273, 'prompt_eval_duration': 8000000, 'eval_count': 16, 'eval_duration': 665000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-8fd566e1-5aaf-4a55-bff2-4e43a679e211-0', tool_calls=[{'name': 'random_number', 'args': {}, 'id': 'ab6fd9ec-8dfb-4e63-bbe8-cabd1a027b20', 'type': 'tool_call'}], usage_metadata={'input_tokens': 273, 'output_tokens': 16, 'total_tokens': 289})]}\n",
      "----\n",
      "{'messages': [ToolMessage(content='59.26', name='random_number', id='4e47f13d-55b8-4a7a-864c-0bd302dca7e7', tool_call_id='ab6fd9ec-8dfb-4e63-bbe8-cabd1a027b20')]}\n",
      "----\n",
      "{'messages': [AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'qwen2.5:7b', 'created_at': '2025-01-16T17:17:15.8395859Z', 'done': True, 'done_reason': 'stop', 'total_duration': 643557200, 'load_duration': 16839100, 'prompt_eval_count': 312, 'prompt_eval_duration': 14000000, 'eval_count': 27, 'eval_duration': 600000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-460a09ad-e295-4706-825d-6a936f34a7b9-0', tool_calls=[{'name': 'upper_case', 'args': {'input': 'FIFTY NINE POINT TWO SIX'}, 'id': 'e5e9f624-13aa-4b63-8136-74b87ade42ba', 'type': 'tool_call'}], usage_metadata={'input_tokens': 312, 'output_tokens': 27, 'total_tokens': 339})]}\n",
      "----\n",
      "{'messages': [ToolMessage(content='FIFTY NINE POINT TWO SIX', name='upper_case', id='79347773-b37d-4876-a89b-3b7de37873dd', tool_call_id='e5e9f624-13aa-4b63-8136-74b87ade42ba')]}\n",
      "----\n",
      "{'messages': [AIMessage(content='The random number generated is \"FIFTY NINE POINT TWO SIX\".', additional_kwargs={}, response_metadata={'model': 'qwen2.5:7b', 'created_at': '2025-01-16T17:17:16.2530247Z', 'done': True, 'done_reason': 'stop', 'total_duration': 409344800, 'load_duration': 16873800, 'prompt_eval_count': 364, 'prompt_eval_duration': 12000000, 'eval_count': 16, 'eval_duration': 368000000, 'message': Message(role='assistant', content='The random number generated is \"FIFTY NINE POINT TWO SIX\".', images=None, tool_calls=None)}, id='run-51dc4e27-40b7-495f-973a-0c43037f5905-0', usage_metadata={'input_tokens': 364, 'output_tokens': 16, 'total_tokens': 380})]}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"messages\": \"give me a random number and then write in upper case words.\"}\n",
    "for s in app.stream(inputs):\n",
    "    print(list(s.values())[0])\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panya\\AppData\\Local\\Temp\\ipykernel_7208\\3331265696.py:3: LangGraphDeprecationWarning: ToolExecutor is deprecated as of version 0.2.0 and will be removed in 0.3.0. Use langgraph.prebuilt.ToolNode instead.\n",
      "  tool_executor = ToolExecutor(tools)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "_execute(tags=None, recurse=True, func_accepts_config=True, func_accepts={'writer': False, 'store': False}, tools=[StructuredTool(name='lower_case', description='Returns the input as all lower case.', args_schema=<class 'langchain_core.utils.pydantic.lower_case'>, return_direct=True, func=<function to_lower_case at 0x000002263A376340>), StructuredTool(name='random_number', description='Returns a random number between 0-100.', args_schema=<class 'langchain_core.utils.pydantic.random_number'>, return_direct=True, func=<function random_number_maker at 0x000002263A375DA0>)], tool_map={'lower_case': StructuredTool(name='lower_case', description='Returns the input as all lower case.', args_schema=<class 'langchain_core.utils.pydantic.lower_case'>, return_direct=True, func=<function to_lower_case at 0x000002263A376340>), 'random_number': StructuredTool(name='random_number', description='Returns a random number between 0-100.', args_schema=<class 'langchain_core.utils.pydantic.random_number'>, return_direct=True, func=<function random_number_maker at 0x000002263A375DA0>)}, invalid_tool_msg_template='{requested_tool_name} is not a valid tool, try one of [{available_tool_names_str}].')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.prebuilt.tool_executor import ToolExecutor\n",
    "\n",
    "tool_executor = ToolExecutor(tools)\n",
    "tool_executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, List, Union\n",
    "from langchain_core.agents import AgentAction, AgentFinish\n",
    "from langchain_core.messages import BaseMessage\n",
    "import operator\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "   # The input string\n",
    "   input: str\n",
    "   # The list of previous messages in the conversation\n",
    "   chat_history: list[BaseMessage]\n",
    "   # The outcome of a given call to the agent\n",
    "   # Needs `None` as a valid type, since this is what this will start as\n",
    "   agent_outcome: Union[AgentAction, AgentFinish, None]\n",
    "   # List of actions and corresponding observations\n",
    "   # Here we annotate this with `operator.add` to indicate that operations to\n",
    "   # this state should be ADDED to the existing values (not overwrite it)\n",
    "   intermediate_steps: Annotated[list[tuple[AgentAction, str]], operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the agent/graph\n",
    "def run_agent(state: AgentState):\n",
    "    print(state)\n",
    "    # print(state)\n",
    "    message = prompt.format_prompt(\n",
    "        input=state['input'], \n",
    "        chat_history=state['chat_history'],\n",
    "        agent_scratchpad=[]\n",
    "    ).to_messages()\n",
    "    agent_outcome = llm_with_tools.invoke(message)\n",
    "    return {\"agent_outcome\": agent_outcome}\n",
    "\n",
    "# Define the function to execute tools\n",
    "def execute_tools(state: AgentState):\n",
    "    # Get the most recent agent_outcome - this is the key added in the `agent` above\n",
    "    agent_action = state['agent_outcome']\n",
    "    # Execute the tool\n",
    "    output = tool_executor.invoke(agent_action)\n",
    "    print(f\"The agent action is {agent_action}\")\n",
    "    print(f\"The tool result is: {output}\")\n",
    "    # Return the output\n",
    "    return {\"intermediate_steps\": [(agent_action, str(output))]}\n",
    "\n",
    "# Define logic that will be used to determine which conditional edge to go down\n",
    "def should_continue(state: AgentState):\n",
    "    # If the agent outcome is an AgentFinish, then we return `exit` string\n",
    "    # This will be used when setting up the graph to define the flow\n",
    "    if isinstance(state['agent_outcome'], AgentFinish):\n",
    "        return \"end\"\n",
    "    # Otherwise, an AgentAction is returned\n",
    "    # Here we return `continue` string\n",
    "    # This will be used when setting up the graph to define the flow\n",
    "    else:\n",
    "        return \"continue\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Define the two nodes we will cycle between\n",
    "workflow.add_node(\"agent\", run_agent)\n",
    "workflow.add_node(\"action\", execute_tools)\n",
    "\n",
    "# Set the entrypoint as `agent`\n",
    "# This means that this node is the first one called\n",
    "workflow.set_entry_point(\"agent\")\n",
    "\n",
    "# We now add a conditional edge\n",
    "workflow.add_conditional_edges(\n",
    "    # First, we define the start node. We use `agent`.\n",
    "    # This means these are the edges taken after the `agent` node is called.\n",
    "    \"agent\",\n",
    "    # Next, we pass in the function that will determine which node is called next.\n",
    "    should_continue,\n",
    "    # Finally we pass in a mapping.\n",
    "    # The keys are strings, and the values are other nodes.\n",
    "    # END is a special node marking that the graph should finish.\n",
    "    # What will happen is we will call `should_continue`, and then the output of that\n",
    "    # will be matched against the keys in this mapping.\n",
    "    # Based on which one it matches, that node will then be called.\n",
    "    {\n",
    "        # If `tools`, then we call the tool node.\n",
    "        \"continue\": \"action\",\n",
    "        # Otherwise we finish.\n",
    "        \"end\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "# We now add a normal edge from `tools` to `agent`.\n",
    "# This means that after `tools` is called, `agent` node is called next.\n",
    "workflow.add_edge('action', 'agent')\n",
    "\n",
    "# Finally, we compile it!\n",
    "# This compiles it into a LangChain Runnable,\n",
    "# meaning you can use it as you would any other runnable\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': <langgraph.channels.last_value.LastValue at 0x262862c34c0>,\n",
       " 'chat_history': <langgraph.channels.last_value.LastValue at 0x262862c3400>,\n",
       " 'agent_outcome': <langgraph.channels.last_value.LastValue at 0x262862c3440>,\n",
       " 'intermediate_steps': <langgraph.channels.binop.BinaryOperatorAggregate at 0x262861e97c0>}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'give me a random number and then write in words and make it lower case.', 'chat_history': [], 'intermediate_steps': []}\n",
      "{'agent_outcome': AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'qwen2.5:7b', 'created_at': '2025-01-16T16:46:36.7494865Z', 'done': True, 'done_reason': 'stop', 'total_duration': 772764800, 'load_duration': 18392000, 'prompt_eval_count': 212, 'prompt_eval_duration': 163000000, 'eval_count': 16, 'eval_duration': 587000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-7f1f376c-43ff-42ea-9d80-7512c5b92e52-0', tool_calls=[{'name': 'random_number', 'args': {}, 'id': '112581eb-35a3-4ec5-9b02-654751f63e6d', 'type': 'tool_call'}], usage_metadata={'input_tokens': 212, 'output_tokens': 16, 'total_tokens': 228})}\n",
      "----\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'AIMessage' object has no attribute 'tool'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgive me a random number and then write in words and make it lower case.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchat_history\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# \"agent_scratchpad\" : []\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     }\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m----\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\panya\\anaconda3\\envs\\chat\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:1660\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;66;03m# channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[0;32m   1657\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[0;32m   1658\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps\u001b[39;00m\n\u001b[0;32m   1659\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[1;32m-> 1660\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1661\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtasks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1662\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1663\u001b[0m \u001b[43m            \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1664\u001b[0m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1665\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1666\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[0;32m   1667\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1668\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\panya\\anaconda3\\envs\\chat\\Lib\\site-packages\\langgraph\\pregel\\runner.py:167\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[0;32m    165\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 167\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_SEND\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\Users\\panya\\anaconda3\\envs\\chat\\Lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[0;32m     38\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     42\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[1;32mc:\\Users\\panya\\anaconda3\\envs\\chat\\Lib\\site-packages\\langgraph\\utils\\runnable.py:408\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    404\u001b[0m config \u001b[38;5;241m=\u001b[39m patch_config(\n\u001b[0;32m    405\u001b[0m     config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    406\u001b[0m )\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 408\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    410\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32mc:\\Users\\panya\\anaconda3\\envs\\chat\\Lib\\site-packages\\langgraph\\utils\\runnable.py:184\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    183\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[1;32m--> 184\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[1;32mIn[7], line 18\u001b[0m, in \u001b[0;36mexecute_tools\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m     16\u001b[0m agent_action \u001b[38;5;241m=\u001b[39m state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124magent_outcome\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Execute the tool\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mtool_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent_action\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe agent action is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00magent_action\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe tool result is: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\panya\\anaconda3\\envs\\chat\\Lib\\site-packages\\langgraph\\utils\\runnable.py:184\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    183\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[1;32m--> 184\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32mc:\\Users\\panya\\anaconda3\\envs\\chat\\Lib\\site-packages\\langgraph\\prebuilt\\tool_executor.py:113\u001b[0m, in \u001b[0;36mToolExecutor._execute\u001b[1;34m(self, tool_invocation, config)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_execute\u001b[39m(\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28mself\u001b[39m, tool_invocation: ToolInvocationInterface, config: RunnableConfig\n\u001b[0;32m    112\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtool_invocation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtool\u001b[49m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtool_map:\n\u001b[0;32m    114\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minvalid_tool_msg_template\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    115\u001b[0m             requested_tool_name\u001b[38;5;241m=\u001b[39mtool_invocation\u001b[38;5;241m.\u001b[39mtool,\n\u001b[0;32m    116\u001b[0m             available_tool_names_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([t\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtools]),\n\u001b[0;32m    117\u001b[0m         )\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\panya\\anaconda3\\envs\\chat\\Lib\\site-packages\\pydantic\\main.py:891\u001b[0m, in \u001b[0;36mBaseModel.__getattr__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m    888\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(item)  \u001b[38;5;66;03m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[0;32m    889\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    890\u001b[0m     \u001b[38;5;66;03m# this is the current error\u001b[39;00m\n\u001b[1;32m--> 891\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'AIMessage' object has no attribute 'tool'",
      "\u001b[0mDuring task with name 'action' and id '225703b6-8235-4848-e47a-35a580f5ab6a'"
     ]
    }
   ],
   "source": [
    "inputs = {\n",
    "    \"input\": \"give me a random number and then write in words and make it lower case.\", \n",
    "    \"chat_history\": [],\n",
    "    # \"agent_scratchpad\" : []\n",
    "    }\n",
    "for s in app.stream(inputs):\n",
    "    print(list(s.values())[0])\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "    message = prompt.format_prompt(\n",
    "        input=inputs['input'], \n",
    "        chat_history=inputs['chat_history'],\n",
    "        agent_scratchpad=[]\n",
    "    ).to_messages()\n",
    "    agent_outcome = llm_with_tools.invoke(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'qwen2.5:7b', 'created_at': '2025-01-16T16:47:29.0864154Z', 'done': True, 'done_reason': 'stop', 'total_duration': 724778600, 'load_duration': 17363100, 'prompt_eval_count': 212, 'prompt_eval_duration': 265000000, 'eval_count': 16, 'eval_duration': 439000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-39e1772f-d109-4574-bc3f-e7ee98d52aff-0', tool_calls=[{'name': 'random_number', 'args': {}, 'id': 'fea2228b-2acd-4e0e-95e3-1799ec250430', 'type': 'tool_call'}], usage_metadata={'input_tokens': 212, 'output_tokens': 16, 'total_tokens': 228})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
